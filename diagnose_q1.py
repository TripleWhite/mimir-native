#!/usr/bin/env python3
"""
è¯Šæ–­æ£€ç´¢å’Œç­”æ¡ˆç”Ÿæˆé—®é¢˜
"""
import os
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import json
from mimir_native import MimirMemory
from mimir_native.llm_client import BedrockClient

def diagnose():
    print("ğŸ” Diagnosing Retrieval & Answer Generation")
    
    # åˆå§‹åŒ–
    mimir = MimirMemory(db_path=':memory:')
    llm = BedrockClient()
    print("âœ… Initialized\n")
    
    # æ·»åŠ æµ‹è¯•æ•°æ®ï¼ˆæ¨¡æ‹Ÿ LoCoMo æ•°æ®ï¼‰
    test_memories = [
        "Caroline: I visited the LGBTQ support group today.",
        "Friend: How was it?",
        "Caroline: It was great, very supportive. The meeting was on 7 May 2023.",
        "Caroline: I'm planning to pursue psychology and counseling certification.",
        "Caroline: I researched adoption agencies recently.",
        "Caroline: As a transgender woman, I want to help others.",
    ]
    
    print("ğŸ“¥ Adding memories...")
    for m in test_memories:
        result = mimir.add_content(m, content_type='text', user_id='test')
        print(f"  -> {len(result)} memories")
    
    # æµ‹è¯• Q1
    query = "When did Caroline go to the LGBTQ support group?"
    print(f"\nğŸ” Query: {query}")
    
    # è·å–æ£€ç´¢ç»“æœ
    results = mimir.query(query, user_id='test', top_k=5)
    print(f"\nğŸ“Š Retrieved {len(results)} results:")
    
    contexts = []
    for i, r in enumerate(results, 1):
        content = r.memory.content if hasattr(r, 'memory') else str(r)
        score = r.score if hasattr(r, 'score') else 0
        print(f"  [{i}] {content}")
        print(f"      Score: {score:.3f}")
        contexts.append(content)
    
    # æ„å»º prompt
    context_text = "\n".join(contexts)
    prompt = f"""Based on the following context, answer the question concisely.

Context:
{context_text}

Question: {query}

Answer:"""
    
    print(f"\nğŸ“ Prompt (first 500 chars):")
    print(prompt[:500])
    
    # ç”Ÿæˆç­”æ¡ˆ
    print(f"\nğŸ¤– Generating answer...")
    try:
        answer = llm.invoke_mistral(prompt)
        print(f"Answer: {answer}")
        
        # åˆ†æé—®é¢˜
        print(f"\nğŸ“‹ Analysis:")
        if "does not provide" in answer.lower() or "no information" in answer.lower():
            print("  âš ï¸  LLM claims no info despite retrieval")
            print(f"  Context contains '7 May': {'7 May' in context_text}")
            print(f"  Context contains 'support group': {'support group' in context_text.lower()}")
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    diagnose()
