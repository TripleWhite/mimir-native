# Supermemory SOTA æ¶æ„æ·±åº¦è§£æ

**æ¥æº**: https://supermemory.ai/research  
**åŸºå‡†**: LongMemEval_s (æ¯” LoCoMo æ›´ä¸¥æ ¼)  
**æ€§èƒ½**: Multi Session 71.43%, Temporal Reasoning 76.69%

---

## ğŸ† æ ¸å¿ƒåˆ›æ–°

### 1. Chunk-based Ingestion + Contextual Memories

**é—®é¢˜**: æ ‡å‡† RAG æ£€ç´¢åŸå§‹ chunks ç¼ºä¹ä¸Šä¸‹æ–‡

**è§£å†³æ–¹æ¡ˆ**:
```
åŸå§‹å¯¹è¯ â†’ Chunking â†’ Memory Generation â†’ å­˜å‚¨
                â†“
         Contextual Retrieval (Anthropic)
         
Memory = Atomic piece of information
       + è§£ææ¨¡ç³Šå¼•ç”¨
       + ä¸Šä¸‹æ–‡ä¿¡æ¯
```

**Mimir-Native åº”ç”¨**:
```python
class ContextualMemoryGenerator:
    def generate_memory(self, chunk: str, context: str) -> Memory:
        """
        ç”Ÿæˆå¸¦ä¸Šä¸‹æ–‡çš„è®°å¿†
        ä¸æ˜¯ç®€å•å­˜å‚¨ chunkï¼Œè€Œæ˜¯æå– atomic fact
        """
        atomic_fact = self.llm.extract_fact(chunk, context)
        return Memory(
            content=atomic_fact,
            source_chunk=chunk,
            context_summary=context[:200]
        )
```

---

### 2. Relational Versioning (çŸ¥è¯†ç‰ˆæœ¬æ§åˆ¶)

**ä¸‰ç§å…³ç³»ç±»å‹**:

| å…³ç³» | æè¿° | ç¤ºä¾‹ |
|------|------|------|
| **updates** | çŠ¶æ€çªå˜ï¼Œå¤„ç†çŸ›ç›¾ | "favorite color is now Green" â†’ æ›´æ–° Blue |
| **extends** | è¡¥å……ç»†èŠ‚ï¼Œæ— çŸ›ç›¾ | æ·»åŠ  job title åˆ° employment memory |
| **derives** | äºŒé˜¶é€»è¾‘æ¨æ–­ | ä»å¤šä¸ª memories æ¨æ–­æ–°ä¿¡æ¯ |

**Mimir-Native åº”ç”¨**:
```python
class RelationalMemoryGraph:
    def add_relation(self, new_memory: Memory, existing: Memory):
        if self.is_contradiction(new_memory, existing):
            relation = RelationType.UPDATES
            self.version_history[existing.id].append(new_memory)
        elif self.is_supplement(new_memory, existing):
            relation = RelationType.EXTENDS
        elif self.is_inference(new_memory, [existing]):
            relation = RelationType.DERIVES
            
        self.graph.add_edge(existing, new_memory, relation)
```

---

### 3. Temporal Grounding (åŒé‡æ—¶é—´æˆ³)

**å…³é”®æ´å¯Ÿ**: æ¯ä¸ªè®°å¿†æœ‰ä¸¤ä¸ªæ—¶é—´æˆ³

```python
@dataclass
class TemporalMetadata:
    documentDate: datetime  # å¯¹è¯å‘ç”Ÿæ—¶é—´
    eventDate: List[datetime]  # äº‹ä»¶å®é™…å‘ç”Ÿæ—¶é—´
```

**ç”¨é€”**:
- **documentDate**: è®¡ç®—ç›¸å¯¹æ—¶é—´ ("yesterday" relative to documentDate)
- **eventDate**: çœŸå®äº‹ä»¶æ—¶åº

**Mimir-Native åº”ç”¨**:
```python
class TemporalGrounding:
    def parse_relative_time(self, text: str, document_date: datetime) -> datetime:
        """
        "yesterday" â†’ document_date - 1 day
        NOT current date!
        """
        pass
    
    def extract_event_dates(self, text: str) -> List[datetime]:
        """æå–æ–‡æœ¬ä¸­æ‰€æœ‰äº‹ä»¶æ—¶é—´"""
        pass
```

---

### 4. Hybrid Search Strategy (æ··åˆæœç´¢)

**ä¸¤é˜¶æ®µæœç´¢**:

```
é˜¶æ®µ 1: Semantic Search on Memories
        â†“
   æ‰¾åˆ°ç›¸å…³ memory (é«˜ signal, ä½ noise)
   
é˜¶æ®µ 2: Inject Source Chunk
        â†“
   è¿”å›åŸå§‹ chunk ç»™ LLM (finer details)
```

**ä¼˜åŠ¿**:
- Memories æ˜¯ atomic facts â†’ é«˜ç²¾ç¡®åº¦æ£€ç´¢
- Chunks æä¾›å®Œæ•´ä¸Šä¸‹æ–‡ â†’ LLM æœ‰è¶³å¤Ÿç»†èŠ‚

**Mimir-Native åº”ç”¨**:
```python
class TwoStageRetriever:
    def retrieve(self, query: str, top_k: int = 10):
        # Stage 1: Search memories
        memories = self.memory_store.search(query, top_k=top_k*2)
        
        # Stage 2: Get source chunks
        results = []
        for mem in memories:
            chunk = self.chunk_store.get(mem.source_chunk_id)
            results.append({
                'memory': mem.content,
                'chunk': chunk.content,
                'temporal': chunk.temporal_metadata
            })
        
        return results
```

---

## ğŸ“Š LongMemEval åŸºå‡†

### ä¸ºä»€ä¹ˆæ¯” LoCoMo æ›´ä¸¥æ ¼ï¼Ÿ

| ç‰¹æ€§ | LoCoMo | LongMemEval |
|------|--------|-------------|
| ä¸Šä¸‹æ–‡é•¿åº¦ | æœ‰é™ | 115k+ tokens |
| çŸ¥è¯†æ›´æ–° | âŒ | âœ… (overwrite old info) |
| äººç±»-åŠ©æ‰‹å¯¹è¯ | âŒ | âœ… (æ›´åƒçœŸå®ä½¿ç”¨) |
| å™ªå£°ç¯å¢ƒ | ä½ | é«˜ |

### è¯„ä¼°ç±»åˆ«

1. **single-session-user**: æ£€ç´¢ç”¨æˆ·æåˆ°çš„å†…å®¹
2. **single-session-assistant**: æ£€ç´¢åŠ©æ‰‹æåˆ°çš„å†…å®¹
3. **single-session-preference**: æå–ç”¨æˆ·åå¥½
4. **multi-session**: è·¨ä¼šè¯æ¨ç†
5. **knowledge-update**: çŸ¥è¯†æ›´æ–°å¤„ç†
6. **temporal-reasoning**: æ—¶åºæ¨ç†

---

## ğŸ› ï¸ å®ç°è·¯çº¿å›¾

### Phase 1: Contextual Memories (ç«‹å³)

```python
# ä¿®æ”¹ç°æœ‰çš„ fact extraction
class ContextualFactExtractor:
    def extract(self, text: str, context: str) -> List[Memory]:
        prompt = f"""
        Extract atomic facts from this text.
        Resolve any ambiguous references using the context.
        
        Text: {text}
        Context: {context}
        
        Output format:
        - Fact: [clear, standalone fact]
        - Source: [original text span]
        """
        return self.llm.extract(prompt)
```

### Phase 2: Relational Graph (çŸ­æœŸ)

```python
# æ·»åŠ å…³ç³»è·Ÿè¸ª
class MemoryGraph:
    def __init__(self):
        self.nodes: Dict[str, Memory] = {}
        self.edges: List[Relation] = []
        self.versions: Dict[str, List[Memory]] = {}
    
    def add_memory(self, memory: Memory):
        # Check for relations with existing memories
        for existing in self.nodes.values():
            relation = self.detect_relation(memory, existing)
            if relation:
                self.edges.append(Relation(existing, memory, relation))
                
        self.nodes[memory.id] = memory
```

### Phase 3: Temporal Grounding (çŸ­æœŸ)

```python
# å¢å¼º temporal_normalizer.py
class TemporalGrounding:
    def __init__(self):
        self.document_date: Optional[datetime] = None
        self.event_dates: List[datetime] = []
    
    def set_document_date(self, date: datetime):
        """è®¾ç½®æ–‡æ¡£æ—¥æœŸä½œä¸ºç›¸å¯¹æ—¶é—´åŸºå‡†"""
        self.document_date = date
    
    def parse_relative(self, text: str) -> datetime:
        """ç›¸å¯¹äº document_date è§£æ"""
        if "yesterday" in text.lower():
            return self.document_date - timedelta(days=1)
        # ... more patterns
```

### Phase 4: Two-Stage Retrieval (ä¸­æœŸ)

```python
# å®ç°ä¸¤é˜¶æ®µæœç´¢
class SupermemoryRetriever:
    def __init__(self):
        self.memory_index = MemoryIndex()  # è½»é‡çº§ï¼Œé«˜ signal
        self.chunk_index = ChunkIndex()    # å®Œæ•´ chunks
    
    def search(self, query: str):
        # Stage 1: Fast memory search
        memories = self.memory_index.search(query, top_k=20)
        
        # Stage 2: Fetch chunks
        results = []
        for mem in memories:
            chunk = self.chunk_index.get(mem.chunk_id)
            results.append({
                'fact': mem.content,
                'details': chunk.content,
                'when': chunk.temporal
            })
        
        return results
```

---

## ğŸ’¡ å…³é”®æ´å¯Ÿ

### 1. æœ€å°åŒ–è¯­ä¹‰æ­§ä¹‰
> "Supermemory achieves SOTA by minimizing semantic ambiguity"

**æ–¹æ³•**: å°† memories ä¸æ—¶é—´å…ƒæ•°æ®ã€å…³ç³»ã€åŸå§‹ chunks è€¦åˆ

### 2. Session-Based Ingestion
> "We ingest session-by-session, not round-by-round"

**ä¼˜åŠ¿**: ä¿ç•™ä¼šè¯çº§åˆ«çš„ä¸Šä¸‹æ–‡å’Œè¿è´¯æ€§

### 3. Knowledge Chains
é€šè¿‡å…³ç³»é“¾æ¥å½¢æˆçŸ¥è¯†æ¼”åŒ–å†å²

---

## ğŸ“š å‚è€ƒ

- **Supermemory Research**: https://supermemory.ai/research
- **LongMemEval Paper**: Wu et al., 2024
- **Anthropic Contextual Retrieval**: https://www.anthropic.com/engineering/contextual-retrieval
- **Zep Memory**: Rasmussen et al., 2025

---

## ğŸ¯ åº”ç”¨åˆ° Mimir-Native

### ç«‹å³å¯ä»¥åšçš„æ”¹è¿›

1. âœ… **å·²æœ‰**: Evidence-based retrieval (86.1% F1)
2. ğŸ”„ **æ·»åŠ **: Contextual memory generation
3. ğŸ”„ **æ·»åŠ **: Dual-layer timestamp (documentDate + eventDate)
4. ğŸ”„ **æ·»åŠ **: Relation tracking (updates/extends/derives)
5. ğŸ”„ **æ·»åŠ **: Two-stage retrieval (memory â†’ chunk)

### é¢„æœŸæå‡

| æ”¹è¿› | å½“å‰ | é¢„æœŸ |
|------|------|------|
| Contextual Memories | 86.1% | 88%+ |
| Temporal Grounding | 86.1% | 89%+ |
| Relational Graph | 86.1% | 90%+ |

---

*åˆ†æå®Œæˆ: 2026-02-12*
*ä¸‹ä¸€æ­¥: å®ç° Phase 1-2*
