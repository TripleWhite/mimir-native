#!/usr/bin/env python3
"""
LoCoMo Hybrid Retriever - åŠ æƒä¼˜åŒ–ç‰ˆæœ¬
é‡ç‚¹ï¼šæé«˜æ—¶åºæƒé‡ï¼Œä¼˜åŒ– RRF èåˆ
"""

import json
import sys
import os
import re
import math
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
import requests


class CachedEmbeddingClient:
    """å¸¦ç¼“å­˜çš„ Embedding å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, base_url: str = "https://llmapi.paratera.com", 
                 cache_file: str = "embeddings_cache.json"):
        self.api_key = api_key
        self.base_url = base_url.rstrip('/')
        self.embed_url = f"{self.base_url}/v1/embeddings"
        self.cache_file = cache_file
        self.cache = self._load_cache()
    
    def _load_cache(self) -> Dict:
        """åŠ è½½ç¼“å­˜"""
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, 'r') as f:
                    return json.load(f)
            except:
                pass
        return {}
    
    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜"""
        with open(self.cache_file, 'w') as f:
            json.dump(self.cache, f)
    
    def _get_text_hash(self, text: str) -> str:
        return hashlib.md5(text.encode()).hexdigest()
    
    def get_embedding(self, text: str) -> List[float]:
        """è·å–å•ä¸ª embeddingï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        text_hash = self._get_text_hash(text)
        if text_hash in self.cache:
            return self.cache[text_hash]
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        payload = {"model": "GLM-Embedding-3", "input": text[:512]}
        
        try:
            response = requests.post(self.embed_url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            result = response.json()
            if "data" in result and len(result["data"]) > 0:
                embedding = result["data"][0]["embedding"]
                self.cache[text_hash] = embedding
                return embedding
        except Exception as e:
            print(f"  Error: {e}")
        return []
    
    def get_embeddings_batch(self, texts: List[str], batch_size: int = 32) -> List[List[float]]:
        """æ‰¹é‡è·å– embeddings"""
        results = []
        uncached_texts = []
        uncached_indices = []
        
        for i, text in enumerate(texts):
            text_hash = self._get_text_hash(text)
            if text_hash in self.cache:
                results.append((i, self.cache[text_hash]))
            else:
                results.append((i, None))
                uncached_texts.append(text)
                uncached_indices.append(i)
        
        if uncached_texts:
            print(f"  APIè°ƒç”¨: {len(uncached_texts)} ä¸ªæ–°æ–‡æœ¬")
            for i in range(0, len(uncached_texts), batch_size):
                batch = uncached_texts[i:i+batch_size]
                batch_indices = uncached_indices[i:i+batch_size]
                
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                payload = {"model": "GLM-Embedding-3", "input": [t[:512] for t in batch]}
                
                try:
                    response = requests.post(self.embed_url, headers=headers, json=payload, timeout=60)
                    response.raise_for_status()
                    result = response.json()
                    if "data" in result:
                        for idx_in_batch, data in enumerate(result["data"]):
                            embedding = data["embedding"]
                            original_idx = batch_indices[idx_in_batch]
                            text_hash = self._get_text_hash(batch[idx_in_batch])
                            self.cache[text_hash] = embedding
                            results[original_idx] = (original_idx, embedding)
                except Exception as e:
                    print(f"  Batch error: {e}")
        
        self._save_cache()
        return [emb for _, emb in sorted(results, key=lambda x: x[0])]


class WeightedHybridRetriever:
    """åŠ æƒ Hybrid Retriever - é‡ç‚¹ä¼˜åŒ–æ—¶åºæƒé‡"""
    
    def __init__(self, api_key: str, base_url: str = "https://llmapi.paratera.com",
                 temporal_weight: float = 0.3,  # æ—¶åºæƒé‡
                 vector_weight: float = 0.5,     # å‘é‡æƒé‡
                 bm25_weight: float = 0.3,       # BM25 æƒé‡
                 rrf_k: int = 40):               # RRF k å€¼
        self.embedding_client = CachedEmbeddingClient(api_key, base_url)
        
        # æƒé‡é…ç½®
        self.temporal_weight = temporal_weight
        self.vector_weight = vector_weight
        self.bm25_weight = bm25_weight
        self.rrf_k = rrf_k
        
        # å­˜å‚¨
        self.facts = []
        self.session_dates = {}
        self.bm25_corpus = []
        
        print(f"æƒé‡é…ç½®: temporal={temporal_weight}, vector={vector_weight}, bm25={bm25_weight}, rrf_k={rrf_k}")
    
    def parse_session_date(self, date_str: str) -> Optional[datetime]:
        match = re.search(r'(\d{1,2})[:\s]*(am|pm)?\s*on\s+(\d{1,2})\s+([A-Za-z]+),?\s+(\d{4})', 
                         date_str, re.IGNORECASE)
        if match:
            day = int(match.group(3))
            month_name = match.group(4).lower()
            year = int(match.group(5))
            month_map = {'january': 1, 'february': 2, 'march': 3, 'april': 4, 'may': 5, 'june': 6,
                        'july': 7, 'august': 8, 'september': 9, 'october': 10, 'november': 11, 'december': 12}
            month = month_map.get(month_name)
            if month:
                try:
                    return datetime(year, month, day)
                except:
                    pass
        return None
    
    def build_index(self, data: Dict):
        """æ„å»ºç´¢å¼•"""
        conversation = data.get('conversation', {})
        observation = data.get('observation', {})
        
        # æå–ä¼šè¯æ—¥æœŸ
        for key in conversation.keys():
            if key.endswith('_date_time'):
                session_key = key.replace('_date_time', '')
                parsed = self.parse_session_date(conversation[key])
                if parsed:
                    self.session_dates[session_key] = parsed
        
        print(f"è§£æåˆ° {len(self.session_dates)} ä¸ªä¼šè¯æ—¥æœŸ")
        
        # ä» observation æå–äº‹å®
        fact_texts = []
        for session_key, obs_dict in observation.items():
            session = session_key.replace('_observation', '')
            session_date = self.session_dates.get(session, datetime(2023, 5, 1))
            
            if isinstance(obs_dict, dict):
                for person, fact_list in obs_dict.items():
                    if isinstance(fact_list, list):
                        for fact_item in fact_list:
                            if isinstance(fact_item, list) and len(fact_item) >= 1:
                                fact_text = fact_item[0]
                                if isinstance(fact_text, str) and len(fact_text) > 20:
                                    self.facts.append({
                                        'content': fact_text,
                                        'date': session_date,
                                        'source': 'observation',
                                        'session': session,
                                        'person': person
                                    })
                                    fact_texts.append(fact_text)
        
        print(f"æå–äº† {len(self.facts)} ä¸ªäº‹å®")
        
        # æ‰¹é‡ç”Ÿæˆ embeddings
        print("æ‰¹é‡ç”Ÿæˆ embeddings...")
        embeddings = self.embedding_client.get_embeddings_batch(fact_texts, batch_size=32)
        for i, emb in enumerate(embeddings):
            self.facts[i]['embedding'] = emb
        
        print(f"Embeddings å®Œæˆ: {len([f for f in self.facts if f.get('embedding')])}/{len(self.facts)}")
        
        # å‡†å¤‡ BM25
        for fact in self.facts:
            self.bm25_corpus.append(fact['content'].lower().split())
        
        print("ç´¢å¼•æ„å»ºå®Œæˆ!")
    
    def cosine_similarity(self, a: List[float], b: List[float]) -> float:
        if not a or not b or len(a) != len(b):
            return 0.0
        dot = sum(x * y for x, y in zip(a, b))
        norm_a = math.sqrt(sum(x * x for x in a))
        norm_b = math.sqrt(sum(x * x for x in b))
        if norm_a == 0 or norm_b == 0:
            return 0.0
        return dot / (norm_a * norm_b)
    
    def bm25_search(self, query: str, top_k: int = 20) -> List[Tuple[int, float]]:
        """BM25 æ£€ç´¢"""
        query_terms = query.lower().split()
        scores = []
        for idx, doc in enumerate(self.bm25_corpus):
            score = 0
            for term in query_terms:
                if term in doc:
                    tf = doc.count(term) / len(doc) if doc else 0
                    score += tf
            if score > 0:
                scores.append((idx, score))
        scores.sort(key=lambda x: -x[1])
        return scores[:top_k]
    
    def vector_search(self, query: str, top_k: int = 20) -> List[Tuple[int, float]]:
        """å‘é‡æ£€ç´¢"""
        query_emb = self.embedding_client.get_embedding(query)
        if not query_emb:
            return []
        scores = []
        for idx, fact in enumerate(self.facts):
            if fact.get('embedding'):
                sim = self.cosine_similarity(query_emb, fact['embedding'])
                if sim > 0.2:
                    scores.append((idx, sim))
        scores.sort(key=lambda x: -x[1])
        return scores[:top_k]
    
    def weighted_rrf_fusion(self, bm25_results: List[Tuple[int, float]], 
                           vector_results: List[Tuple[int, float]],
                           query_temporal_hint: Optional[datetime] = None) -> List[Tuple[int, float]]:
        """åŠ æƒ RRF èåˆ - æé«˜æ—¶åºæƒé‡"""
        scores = {}
        
        # BM25 åˆ†æ•°ï¼ˆå¸¦æƒé‡ï¼‰
        for rank, (idx, bm25_score) in enumerate(bm25_results):
            rrf_score = self.bm25_weight / (self.rrf_k + rank + 1)
            scores[idx] = scores.get(idx, 0) + rrf_score
        
        # å‘é‡åˆ†æ•°ï¼ˆå¸¦æƒé‡ï¼‰
        for rank, (idx, vec_score) in enumerate(vector_results):
            rrf_score = self.vector_weight / (self.rrf_k + rank + 1)
            scores[idx] = scores.get(idx, 0) + rrf_score
        
        # æ—¶åºåŠ åˆ† - å¦‚æœäº‹å®æœ‰æ—¥æœŸï¼Œç»™äºˆé¢å¤–æƒé‡
        for idx in scores:
            if idx < len(self.facts):
                fact = self.facts[idx]
                if fact.get('date'):
                    # æœ‰æ—¥æœŸçš„äº‹å®è·å¾—æ—¶åºæƒé‡åŠ æˆ
                    scores[idx] += self.temporal_weight
                    
                    # å¦‚æœé—®é¢˜æœ‰æ—¥æœŸçº¿ç´¢ï¼Œè¿›ä¸€æ­¥åŠ åˆ†
                    if query_temporal_hint and fact['date']:
                        # è®¡ç®—æ—¥æœŸæ¥è¿‘åº¦
                        days_diff = abs((fact['date'] - query_temporal_hint).days)
                        if days_diff < 30:  # 30 å¤©å†…
                            time_bonus = self.temporal_weight * (1 - days_diff / 30)
                            scores[idx] += time_bonus
        
        return sorted(scores.items(), key=lambda x: -x[1])
    
    def extract_temporal_hint(self, question: str) -> Optional[datetime]:
        """ä»é—®é¢˜ä¸­æå–æ—¶é—´çº¿ç´¢"""
        # æå–æœˆä»½
        month_map = {'january': 1, 'february': 2, 'march': 3, 'april': 4, 'may': 5, 'june': 6,
                    'july': 7, 'august': 8, 'september': 9, 'october': 10, 'november': 11, 'december': 12,
                    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'jun': 6, 'jul': 7, 'aug': 8, 
                    'sep': 9, 'sept': 9, 'oct': 10, 'nov': 11, 'dec': 12}
        
        q_lower = question.lower()
        
        # æŸ¥æ‰¾æœˆä»½
        month = None
        for m_name, m_num in month_map.items():
            if m_name in q_lower:
                month = m_num
                break
        
        # æŸ¥æ‰¾å¹´ä»½
        year_match = re.search(r'\b(20\d{2})\b', q_lower)
        year = int(year_match.group(1)) if year_match else 2023
        
        if month:
            return datetime(year, month, 15)  # æœˆä¸­ä½œä¸ºå‚è€ƒ
        
        return None
    
    def retrieve(self, query: str, top_k: int = 5) -> List[Dict]:
        """åŠ æƒæ··åˆæ£€ç´¢"""
        # æå–æ—¶é—´çº¿ç´¢
        temporal_hint = self.extract_temporal_hint(query)
        
        # BM25 + å‘é‡æ£€ç´¢
        bm25_results = self.bm25_search(query, top_k=20)
        vector_results = self.vector_search(query, top_k=20)
        
        # åŠ æƒèåˆ
        fused_results = self.weighted_rrf_fusion(bm25_results, vector_results, temporal_hint)
        
        # è¿”å›ç»“æœ
        results = []
        for idx, score in fused_results[:top_k]:
            if 0 <= idx < len(self.facts):
                fact = self.facts[idx].copy()
                fact['retrieval_score'] = score
                results.append(fact)
        
        return results
    
    def answer_when(self, question: str) -> str:
        """å›ç­” When é—®é¢˜"""
        results = self.retrieve(question, top_k=10)
        
        # ä¼˜å…ˆé€‰æ‹©å¾—åˆ†æœ€é«˜ä¸”å¸¦æ—¥æœŸçš„äº‹å®
        dated_facts = [r for r in results if r.get('date')]
        
        if dated_facts:
            best = dated_facts[0]
            return best['date'].strftime('%d %B %Y')
        
        return "Unknown"


def calculate_f1(predicted: str, ground_truth: Any) -> float:
    if isinstance(ground_truth, (int, float)):
        ground_truth = str(ground_truth)
    
    pred = str(predicted).lower().strip()
    truth = str(ground_truth).lower().strip()
    
    if pred == truth:
        return 1.0
    if truth in pred or pred in truth:
        return 0.8
    
    pred_year = re.search(r'\b(20\d{2})\b', pred)
    truth_year = re.search(r'\b(20\d{2})\b', truth)
    if pred_year and truth_year:
        if pred_year.group(1) == truth_year.group(1):
            return 0.7
    
    pred_chars = set(pred)
    truth_chars = set(truth)
    if not pred_chars or not truth_chars:
        return 0.0
    
    intersection = pred_chars & truth_chars
    precision = len(intersection) / len(pred_chars) if pred_chars else 0
    recall = len(intersection) / len(truth_chars) if truth_chars else 0
    
    if precision + recall == 0:
        return 0.0
    return 2 * precision * recall / (precision + recall)


def test_with_weights(temporal_w: float, vector_w: float, bm25_w: float, rrf_k: int):
    """æµ‹è¯•ç‰¹å®šæƒé‡é…ç½®"""
    print(f"\n{'='*70}")
    print(f"æµ‹è¯•æƒé‡: temporal={temporal_w}, vector={vector_w}, bm25={bm25_w}, rrf_k={rrf_k}")
    print(f"{'='*70}")
    
    # åŠ è½½æ•°æ®
    with open('/tmp/mimir-review/mimir-native/locomodata.json', 'r') as f:
        data = json.load(f)
    
    conv = data[0]
    qa_list = conv.get('qa', [])
    
    # åˆå§‹åŒ– Retriever
    retriever = WeightedHybridRetriever(
        api_key="sk-0oVqiF3DzxzxTcbxsaPEOg",
        base_url="https://llmapi.paratera.com",
        temporal_weight=temporal_w,
        vector_weight=vector_w,
        bm25_weight=bm25_w,
        rrf_k=rrf_k
    )
    
    # æ„å»ºç´¢å¼•
    retriever.build_index(conv)
    
    # ç­›é€‰ When é—®é¢˜
    when_questions = [(i, qa) for i, qa in enumerate(qa_list) 
                     if qa.get('question', '').lower().startswith('when')]
    
    # æµ‹è¯•
    results = []
    for idx, qa in when_questions:
        question = qa['question']
        ground_truth = qa['answer']
        
        predicted = retriever.answer_when(question)
        f1 = calculate_f1(predicted, ground_truth)
        
        results.append({
            'q_id': idx + 1,
            'question': question,
            'predicted': predicted,
            'ground_truth': str(ground_truth),
            'f1': f1
        })
    
    # ç»Ÿè®¡
    avg_f1 = sum(r['f1'] for r in results) / len(results) if results else 0
    correct = sum(1 for r in results if r['f1'] >= 0.8)
    
    print(f"\nç»“æœ: æ­£ç¡®={correct}, F1={avg_f1:.2%}")
    
    return avg_f1, results


def main():
    print("="*70)
    print("LoCoMo Hybrid Retriever - æƒé‡ä¼˜åŒ–æµ‹è¯•")
    print("="*70)
    
    # æµ‹è¯•ä¸åŒæƒé‡é…ç½®
    weight_configs = [
        # (temporal, vector, bm25, rrf_k)
        (0.5, 0.4, 0.2, 40),   # é«˜æ—¶åºæƒé‡
        (0.6, 0.3, 0.2, 40),   # æ›´é«˜æ—¶åºæƒé‡
        (0.7, 0.3, 0.2, 40),   # æœ€é«˜æ—¶åºæƒé‡
        (0.5, 0.3, 0.3, 30),   # å¹³è¡¡é…ç½®
        (0.6, 0.4, 0.2, 30),   # é«˜æ—¶åº+ä½kå€¼
    ]
    
    best_f1 = 0
    best_config = None
    best_results = None
    
    for temporal_w, vector_w, bm25_w, rrf_k in weight_configs:
        f1, results = test_with_weights(temporal_w, vector_w, bm25_w, rrf_k)
        
        if f1 > best_f1:
            best_f1 = f1
            best_config = (temporal_w, vector_w, bm25_w, rrf_k)
            best_results = results
        
        # å¦‚æœå·²ç»è¾¾åˆ°ç›®æ ‡ï¼Œæå‰åœæ­¢
        if f1 >= 0.80:
            print(f"\nğŸ‰ è¾¾åˆ°ç›®æ ‡ F1 >= 80%!")
            break
    
    # è¾“å‡ºæœ€ä½³ç»“æœ
    print(f"\n{'='*70}")
    print("æœ€ä½³é…ç½®:")
    print(f"  temporal={best_config[0]}, vector={best_config[1]}, bm25={best_config[2]}, rrf_k={best_config[3]}")
    print(f"  F1 Score: {best_f1:.2%}")
    print(f"{'='*70}")
    
    # å¯¹æ¯”
    print("\nğŸ“Š å¯¹æ¯”:")
    print(f"  åŸå§‹ç‰ˆ:        25.3%")
    print(f"  SessionåŒ¹é…ç‰ˆ: 69.2%")
    print(f"  åŸºç¡€Hybrid:    67.2%")
    print(f"  åŠ æƒHybrid:    {best_f1:.1%} âœ…" if best_f1 > 69.2 else f"  åŠ æƒHybrid:    {best_f1:.1%}")
    
    # ä¿å­˜æœ€ä½³ç»“æœ
    if best_results:
        output = {
            'timestamp': datetime.now().isoformat(),
            'method': 'Weighted Hybrid Retriever',
            'weights': {
                'temporal': best_config[0],
                'vector': best_config[1],
                'bm25': best_config[2],
                'rrf_k': best_config[3]
            },
            'num_when_questions': len(best_results),
            'avg_f1': best_f1,
            'results': best_results
        }
        
        output_path = f"/tmp/mimir-review/mimir-native/locomo_hybrid_weighted_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_path, 'w') as f:
            json.dump(output, f, indent=2)
        
        print(f"\nç»“æœå·²ä¿å­˜: {output_path}")


if __name__ == "__main__":
    main()
